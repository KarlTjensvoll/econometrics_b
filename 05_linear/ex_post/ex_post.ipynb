{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "from tabulate import tabulate as tabulate\n",
    "import LinearModelsWeek5 as lm\n",
    "import gmm_ante as gmm\n",
    "\n",
    "np.set_printoptions(precision=5)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "# Prepare the data\n",
    "In this problem set we consider the state dependency in female **labour market participation** (LMP). The data dpdat.txt comes from the Panel Survey of Income Dynamics (PSID) for the years 1986-1989. The sample consists of 1,442 women aged between 18 and 55 in 1986 who are married or cohabiting. The variables available are the following:\n",
    "\n",
    "  |*Variable*  | *Content* |\n",
    "  |------------| --------------------------------------------|\n",
    "  |y0          | Participation|\n",
    "  |x1          | Fertility|\n",
    "  |x2          | Children aged 2-6.|\n",
    "  |x5          | Children of the same sex (male or female).|\n",
    " | x7         |  Schooling level 1. |\n",
    "  |x8          | Schooling level 2. |\n",
    "  |x9          | Schooling level 3. |\n",
    "  |x10         | Age |\n",
    "  |x11         | Race |\n",
    "  |y1          | Lagged participation |\n",
    "  |Year        | Year of observation |\n",
    "  |const       | Constant (only ones) |"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Preperation\n",
    "Start by loading the data. **For today we need only y0, y1 and year**. Use the `np.loadtxt` function. Remember to give it the proper delimited. It also has an argument that allows you to choose which column you want to use, see if you can find which one that is."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.loadtxt('dpdat.txt', delimiter=',', usecols=0).reshape(-1, 1)\n",
    "\n",
    "const = np.loadtxt('dpdat.txt', delimiter=',', usecols=-1)\n",
    "y_l = np.loadtxt('dpdat.txt', delimiter=',', usecols=12)\n",
    "year = np.loadtxt('dpdat.txt', delimiter=',', usecols=-2)\n",
    "\n",
    "T = 4\n",
    "\n",
    "x = np.column_stack((const, y_l))\n",
    "\n",
    "ylbl = 'participation'\n",
    "xlbl = ['const', 'lag participation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some variables that we used the last time. Note, these will have my names, you might have made some other names.\n",
    "## Variables used for OLS.\n",
    "def fd(t):\n",
    "    # Create a first difference matrix.\n",
    "    # We also remove the last row, so that we delete the first observation.\n",
    "    D_t = np.eye(t, k=1) - np.eye(t)\n",
    "    return D_t[:-1]\n",
    "D_t = fd(T)\n",
    "yfd = lm.perm(D_t, y)\n",
    "yfd_l = lm.perm(D_t, y_l.reshape(-1, 1))\n",
    "\n",
    "## Variables used for PIV\n",
    "# Second lag\n",
    "def lag(t):\n",
    "    # Create a lag matrix.\n",
    "    # Again remove the first observation, by removing the first row.\n",
    "    L_t = np.eye(t, k=-1)\n",
    "    return L_t[1:]\n",
    "L_t = lag(T)\n",
    "y_2l = lm.perm(L_t, y_l.reshape(-1, 1))\n",
    "\n",
    "# Second lag of FD, and shortened arrays that I use with that second lagged instrument.\n",
    "L_t = lag(T - 1)\n",
    "yfd_l2 = lm.perm(L_t, yfd_l)\n",
    "reduced_year = year[year != 1986]  # Remove first year, so that shape is the same as yfd\n",
    "yfd0 = yfd[reduced_year != 1987]\n",
    "yfd_l0 = yfd_l[reduced_year != 1987]"
   ]
  },
  {
   "source": [
    "# Part 3: System 2SLS\n",
    "As mentioned earlier, we have $LMP_{it-2}^{\\textbf{o}} = (LMP_{i0}, LMP_{i1}, \\dotsc LMP_{it-2})$ available instruments at time $t$. In order to take advantage of these instruments, we could create the following instrument matrix,\n",
    "\n",
    "$$\n",
    "\\mathbf{Z^{\\mathbf{o}}} = \n",
    "\\begin{bmatrix}\n",
    "    y_{i0} & 0 & 0 & 0 & 0 & 0 & \\cdots & 0 \\\\\n",
    "    0 & y_{i0} & y_{i1} & 0 & 0 & 0 & \\cdots & 0 \\\\\n",
    "    0 & 0 & 0 & y_{i0} & y_{i1} & y_{i2} & \\cdots & 0 \\\\\n",
    "    \\vdots  & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & 0 & 0 & 0 & 0 & 0 & \\cdots & \\mathbf{y^o_{it-2}} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{pmatrix}\n",
    "t = 2 \\\\\n",
    "t = 3 \\\\\n",
    "t = 3 \\\\\n",
    "\\vdots \\\\\n",
    "t = T\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "We will use the `gmm` module for part, but parts of the `lm` module will be used in the `gmm` module."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Super short introduction to S2SLS, alse read Wooldridge (2010) chapter 5 and chapter 8\n",
    "\n",
    "Since we have different amount of instruments each period, we are unable to use these instruments using piv. We therefore have to leverage system two stage least square (S2SLS). \n",
    "\n",
    "To recap what (\"normal\") 2SLS looks like, eq. (3) would have been estimated this way if we used 2SLS,\n",
    "* In the first-stage regression, we estimate $\\mathbf{x}_K$ on $\\mathbf{Z}$, and then calculate the predicted $\\hat{\\mathbf{x}}_K$.\n",
    "* We use these predicted $\\hat{\\mathbf{x}}_K$ in our second stage regression, so for eq. (3), this would be to regress $\\mathbf{y}$ on $\\mathbf{x}_1, \\dotsc, \\mathbf{x}_{K-1}, \\hat{\\mathbf{x}}_K$.\n",
    "\n",
    "So for 2SLS, we perform a first stage regression for each time period, and store the predicted $\\hat{\\mathbf{x}}_K$ from each time period. We then combine these predicted observations (and we remember to do it in a way that the time periods are sorted correctly for each person) into one array, and use this in our second stage regression."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 1: Create the level instrument matrix $\\mathbf{Z^{\\mathbf{o}}}$\n",
    "\n",
    "Finish the function `sequential_instruments` in order to create the instrument matrix $\\mathbf{Z^{\\mathbf{o}}}$ using the second lag of LMP in **levels**. Note that you will not have one array that looks like $\\mathbf{Z^{\\mathbf{o}}}$, but an array that have something that looks like $\\mathbf{Z^{\\mathbf{o}}}$ for each individual in the data. Since we have four time periods, and access to $y_{i0}$, you should get three rows of instruments for each individual.\n",
    "\n",
    "If if is too difficult to create the instrument matrix $\\mathbf{Z^{\\mathbf{o}}}$, you could also in this instance hard code it. This can be done by using the year column to do boolean indexing in python. You can then use the `np.hstack` to create the necessary columns for the first stage regressions. Look at *question 2* below if you are uncertain on how many columns you should have for each regression."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n [0. 1. 1. 0. 0. 0.]\n [0. 0. 0. 1. 1. 1.]\n ...\n [1. 0. 0. 0. 0. 0.]\n [0. 1. 1. 0. 0. 0.]\n [0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "instrument_matrix = gmm.sequential_instruments(y_2l, T)\n",
    "print(instrument_matrix)"
   ]
  },
  {
   "source": [
    "To prepeare for next question, I have created an function that retrieves one time period for each person, and store them in seperate arrays, and finaly returns these in a list. (I also keep the array for the all time periods, since we need that for the second stage regression). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_eq_by_eq(x, t):\n",
    "    equation = []\n",
    "    # Reshape, so that each column is each time period\n",
    "    xt = x.reshape(-1, t)\n",
    "\n",
    "    # I then transpose this, so that each time period is in rows\n",
    "    for row in xt.T:\n",
    "        # I then put each time period in a separate array, that I store in the list.\n",
    "        equation.append(row.reshape(-1, 1))\n",
    "    # We need individual observations for all years in the second stage regression,\n",
    "    # so let us keep that at the end of the list.\n",
    "    equation.append(x)\n",
    "    return equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arrays = xy_eq_by_eq(yfd, T-1)\n",
    "x_arrays = xy_eq_by_eq(yfd_l, T-1)"
   ]
  },
  {
   "source": [
    "### Question 2: Use the instruments to perform 2SLS\n",
    "\n",
    "Now that you have the necessary instruments, use these to estimate eq. (2), with all possible lagged levels as instruments.\n",
    "\n",
    "I recommend that you create two functions for this. One that simply performs the first-stage regression given y and x, let's call it `first_stage`, and should return the predicted $\\hat{\\mathbf{x}}_K$, which in this case is the second lagged LMP.\n",
    "\n",
    "The second function, let us call is `system_2sls`, loops over a list of y, x and z arrays that are given as inputs, and performs the `first_stage` regression on each array (remember, each array has all observations from one time period only). Since the `first_stage` function you made returns the predicted $\\hat{\\mathbf{x}}_K$, you need to keep them, and in the end combine them. You can now perform the second-stage regression.\n",
    "\n",
    "So in our example where we use levels, you should perform three first-stage regressions that look like this:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Delta LMP_{i1987} & = \\rho_{11}LMP_{i1986} + u_{it} \\\\\n",
    "\\Delta LMP_{i1988} & = \\rho_{21}LMP_{i1986} + \\rho_{22}LMP_{i1987} + u_{it} \\\\\n",
    "\\Delta LMP_{i1989} & = \\rho_{31}LMP_{i1986} + \\rho_{32}LMP_{i1987} + \\rho_{33}LMP_{i1988} + u_{it} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Then, for each regression, you also need to predict the LMP. These need to be stored and in the end combined, so that you get a column that looks like this,\n",
    "\n",
    "$$\n",
    "\\underset{N(T - 1) \\times 1}{\n",
    "\\begin{pmatrix}\n",
    "    \\Delta \\widehat{LMP}_{1, 1987} \\\\\n",
    "    \\Delta \\widehat{LMP}_{1, 1988} \\\\\n",
    "    \\Delta \\widehat{LMP}_{1, 1989} \\\\\n",
    "    \\Delta \\widehat{LMP}_{2, 1987} \\\\\n",
    "    \\Delta \\widehat{LMP}_{2, 1988} \\\\\n",
    "    \\Delta \\widehat{LMP}_{2, 1989} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\Delta \\widehat{LMP}_{N, 1987} \\\\\n",
    "    \\Delta \\widehat{LMP}_{N, 1988} \\\\\n",
    "    \\Delta \\widehat{LMP}_{N, 1989} \\\\\n",
    "\\end{pmatrix}\n",
    "}\n",
    "$$\n",
    "\n",
    "So in the end, you perform a second stage regression that looks like this\n",
    "\n",
    "$$\n",
    "    \\Delta LMP_{it} = \\rho\\Delta \\widehat{LMP}_{it-1} + \\Delta u_{it}\n",
    "$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have created these helper functions. So if you managed to create the instrument matrix, you can use the iv_eq_by_eq to get columns that give you the correct number of columns for the different time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IV_eq_by_eq(instrument_matrix, reduced_year):\n",
    "    z_1987 = instrument_matrix[reduced_year == 1987, 0].reshape(-1, 1)\n",
    "    z_1988 = instrument_matrix[reduced_year == 1988, 1:3]\n",
    "    z_1989 = instrument_matrix[reduced_year == 1989, 3:]\n",
    "    return (z_1987, z_1988, z_1989)\n",
    "z_arrays = IV_eq_by_eq(instrument_matrix, reduced_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "System 2SLS results\nDependent variable: yfd\n\n         Beta      Se    t-values\n-----  ------  ------  ----------\nyfd_l  0.2390  0.0166     14.3891\nR² = 0.000\nσ² = 0.158\n"
     ]
    }
   ],
   "source": [
    "s2sls_result = gmm.system_2sls(y_arrays, x_arrays, z_arrays)\n",
    "lm.print_table(\n",
    "    ('yfd', ['yfd_l']), s2sls_result, title='System 2SLS results', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "source": [
    "System 2SLS results <br>\n",
    "Dependent variable: yfd\n",
    "\n",
    "|       |   Beta |     Se |   t-values |\n",
    "|-------|--------|--------|------------|\n",
    "| yfd_l | 0.2390 | 0.0166 |    14.3891 |\n",
    "R² = 0.000 <br>\n",
    "σ² = 0.158"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 3\n",
    "Repeat question 1 and 2, but now with first differences as instruments. In other words, perform 2SLS with twice lagged first differences of LMP as instruments. \n",
    "\n",
    "I have given you some of the code if you managed to finish the `gmm.sequential_instruments` function. To create the y, x, and z arrays you use the provided `xy_eq_by_eq` function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_year2 = reduced_year[reduced_year != 1987]\n",
    "instrument_matrix = gmm.sequential_instruments(yfd_l2, T - 1)\n",
    "def IV_eq_by_eq2(instrument_matrix, reduced_year):\n",
    "    z_1988 = instrument_matrix[reduced_year == 1988, 0].reshape(-1, 1)\n",
    "    z_1989 = instrument_matrix[reduced_year == 1989, 1:]\n",
    "    return (z_1988, z_1989)\n",
    "\n",
    "z_arrays = IV_eq_by_eq2(instrument_matrix, reduced_year2)\n",
    "y_arrays = xy_eq_by_eq(yfd0, T-2)\n",
    "x_arrays = xy_eq_by_eq(yfd_l0, T-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "System 2SLS results\nDependent variable: yfd\n\n         Beta      Se    t-values\n-----  ------  ------  ----------\nyfd_l  0.1959  0.0197      9.9622\nR² = 0.000\nσ² = 0.152\n"
     ]
    }
   ],
   "source": [
    "s2sls_result = gmm.system_2sls(y_arrays, x_arrays, z_arrays)\n",
    "lm.print_table(\n",
    "    ('yfd', ['yfd_l']), s2sls_result, title='System 2SLS results', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "source": [
    "Your table should look something like this\n",
    "System 2SLS results <br>\n",
    "Dependent variable: yfd\n",
    "\n",
    "|       |   Beta |     Se |   t-values |\n",
    "|-------|--------|--------|------------|\n",
    "| yfd_l | 0.1959 | 0.0197 |     9.9622 |\n",
    "R² = 0.000 <br>\n",
    "σ² = 0.152"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Part 4: GMM\n",
    "Coming up"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_result = gmm.est_gmm(\n",
    "    W = la.inv(instrument_matrix.T@instrument_matrix), \n",
    "    y = yfd0,\n",
    "    x = yfd_l0,\n",
    "    z = instrument_matrix,\n",
    "    t = T-2,\n",
    "    step=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GMM results\nDependent variable: yfd\n\n         Beta      Se    t-values\n-----  ------  ------  ----------\nyfd_l  0.1959  0.0719      2.7239\nR² = nan\nσ² = 0.152\n"
     ]
    }
   ],
   "source": [
    "lm.print_table(('yfd', ['yfd_l']), gmm_result, title='GMM results', floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}