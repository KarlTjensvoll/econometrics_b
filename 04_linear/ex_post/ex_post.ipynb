{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "from tabulate import tabulate as tabulate\n",
    "import LinearModelsWeek4_ante as lm\n",
    "\n",
    "np.set_printoptions(precision=5)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "# Prepare the data\n",
    "In this problem set we consider the state dependency in female **labour market participation** (LMP). The data dpdat.txt comes from the Panel Survey of Income Dynamics (PSID) for the years 1986-1989. The sample consists of 1,442 women aged between 18 and 55 in 1986 who are married or cohabiting. The variables available are the following:\n",
    "\n",
    "  |*Variable*  | *Content* |\n",
    "  |------------| --------------------------------------------|\n",
    "  |y0          | Participation|\n",
    "  |x1          | Fertility|\n",
    "  |x2          | Children aged 2-6.|\n",
    "  |x5          | Children of the same sex (male or female).|\n",
    " | x7         |  Schooling level 1. |\n",
    "  |x8          | Schooling level 2. |\n",
    "  |x9          | Schooling level 3. |\n",
    "  |x10         | Age |\n",
    "  |x11         | Race |\n",
    "  |y1          | Lagged participation |\n",
    "  |Year        | Year of observation |\n",
    "  |const       | Constant (only ones) |"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Preperation\n",
    "Start by loading the data. **For today we need only y0, y1 and year**. Use the `np.loadtxt` function. Remember to give it the proper delimited. It also has an argument that allows you to choose which column you want to use, see if you can find which one that is."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.loadtxt('dpdat.txt', delimiter=',', usecols=0).reshape(-1, 1)\n",
    "\n",
    "const = np.loadtxt('dpdat.txt', delimiter=',', usecols=-1)\n",
    "y_l = np.loadtxt('dpdat.txt', delimiter=',', usecols=12)\n",
    "year = np.loadtxt('dpdat.txt', delimiter=',', usecols=-2)\n",
    "\n",
    "T = 4\n",
    "\n",
    "x = np.column_stack((const, y_l))\n",
    "\n",
    "ylbl = 'participation'\n",
    "xlbl = ['const', 'lag participation']"
   ]
  },
  {
   "source": [
    "# Part 1: POLS\n",
    "Today we will focus on a parsimonious model of female LMP (econometricians often use \"parsimonious\" to mean a \"simple\"). \n",
    "\n",
    "Consider first the following AR(1) (autoregressive model of order $1$),\n",
    "\n",
    "$$\n",
    "LMP_{it} = \\alpha_0 +  \\rho LMP_{it-1} + c_i + u_{it}, \\quad t = 1, 2, \\dotsc, T \\tag{1}\n",
    "$$\n",
    "\n",
    "As we have seen before, if one does not take into consideration $c_i$ when estimating $\\rho$, one will get biased results. One way to solve this, which is also a common way for AR(1) processes, is to take first-differences. We then have the model,\n",
    "\n",
    "$$\n",
    "\\Delta LMP_{it} = \\rho \\Delta LMP_{it-1} + \\Delta u_{it}, \\quad t = 2, \\dotsc, T \\tag{2}\n",
    "$$\n",
    "\n",
    "This solves the presence of fixed effects."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 1\n",
    "Estimate eq. (1) using POLS. \n",
    "* Are there signs of autocorrelation in female labour participation?\n",
    "* What assumptions are no longer satisfied? What happens with fixed effects when we include a lag?\n",
    "\n",
    "*Note:* We need to use the lagged values for participation. But this time we don't need to lag it ourselves, as it is already given to us in the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN\n",
    "# Estimate the AR(1) model using OLS\n",
    "# Print out in a nice table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_result = lm.estimate(y, x, robust_se=True)\n",
    "lm.print_table(\n",
    "    (ylbl, xlbl), ar1_result, title='AR(1)', floatfmt=['', '.3f', '.5f', '.2f']\n",
    ")"
   ]
  },
  {
   "source": [
    "Your table should look like this:\n",
    "\n",
    "AR(1) <br>\n",
    "Dependent variable: participation\n",
    "\n",
    "|                   |   Beta |      Se |   t-values |\n",
    "|-------------------|--------|---------|------------|\n",
    "| const             |  0.278 | 0.01234 |      22.51 |\n",
    "| lag participation |  0.637 | 0.01303 |      48.89 |\n",
    "R² = 0.403 <br>\n",
    "σ² = 0.106"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 2\n",
    "Estimate eq. (2) using first differences. \n",
    "* What problem does this solve? \n",
    "* What type of exogeneity assumption is used to justify this method of estimation?\n",
    "\n",
    "*Note:* You have to create the first differencing matrix yourself, and use the `perm` function to permutate the dependen and independent variables. <br>\n",
    "*Note 2:* This time you should use robust standard errors. The function is provided to you."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN\n",
    "# Create a first difference matrix\n",
    "# First difference both LMP and lag of LMP\n",
    "# Estimate AR(1) model using OLS and print a nice table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd(t):\n",
    "    # Create a first difference matrix.\n",
    "    # We also remove the last row, so that we delete the first observation.\n",
    "    D_t = np.eye(t, k=1) - np.eye(t)\n",
    "    return D_t[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_t = fd(T)\n",
    "yfd = lm.perm(D_t, y)\n",
    "yfd_l = lm.perm(D_t, y_l.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_diff_result = lm.estimate(yfd, yfd_l, robust_se=True, t=T-1)\n",
    "lm.print_table(\n",
    "    (ylbl, ['lag participation']), \n",
    "    ar1_diff_result, title='FD AR(1)', floatfmt=['', '.3f', '.4f', '.2f']\n",
    ")"
   ]
  },
  {
   "source": [
    "Your table should look like this:\n",
    "\n",
    "FD AR(1) <br>\n",
    "Dependent variable: participation\n",
    "\n",
    "|                   |   Beta |     Se |   t-values |\n",
    "|-------------------|--------|--------|------------|\n",
    "| lag participation | -0.321 | 0.0181 |     -17.76 |\n",
    "R² = 0.105 <br>\n",
    "σ² = 0.117"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Super short introduction to pooled IV (piv)\n",
    "\n",
    "Consider that we want to estimate the effect of $x_K$ on $y$, including $K - 1$ controls, we then have the usual equation,\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{u} \\tag{3}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{X} = (\\mathbf{x}_1, \\dotsc, \\mathbf{x}_K)$. If $\\mathbf{x}_K$ is not exogenous, we can define the instrument vector $\\mathbf{Z} = (\\mathbf{x}_1, \\dotsc, \\mathbf{x}_{K - 1}, \\mathbf{z}_1)$, where $\\mathbf{z}_1$ is an instrument for $\\mathbf{x}_K$. The details and necessary assumptions and conditions are outlined in Wooldridge (2010) (chapter 5).\n",
    "\n",
    "We can estimate eq. (1) by OLS using $z_1$ as an instrument for $x_K$, in order to make it easier for you when writing code, I write it up in matrix notation,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\hat{\\beta}} = (\\mathbf{\\hat{X'}}\\mathbf{\\hat{X}})^{-1} \\mathbf{\\hat{X'}}\\mathbf{Y}, \\tag{4}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{\\hat{X}} = \\mathbf{Z}(\\mathbf{Z'}\\mathbf{Z})^{-1}\\mathbf{Z'}\\mathbf{X}$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Part 2: Pooled IV\n",
    "It should not be a surprise that models (1) and (2) violates the strict exegoneity assumption, but even if we relax this assumption to sequential exegoneity, the FD-estimator remains inconsistent.\n",
    "\n",
    "A solution for this is to use an instrument for $\\Delta LMP_{it-1}$. The biggest issue is to find an instrument that is not only relevant, but also exogenous.\n",
    "\n",
    "We often use an additional lag as instruments. So for $\\Delta LMP_{it-1}$, we can use $LMP_{it-2}$. In general, we have all possible lags available as instruments. So for $\\Delta LMP_{it-1}$ we have, $\n",
    "LMP_{it-2}^{\\textbf{o}} = (LMP_{i0}, LMP_{i1}, \\dotsc LMP_{it-2})$ available as instruments.\n",
    "\n",
    "*Note:* $R^2$ has no meaning in IV-regressions, you can report it if you want to. But I set it to 0."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 1\n",
    "Estimate eq. (2) by using the lag of the independent variable in levels, $z_{it} = LMP_{it-2}$ as an instrument. You need to finish writing the `est_piv` function and a part of the `estimate` function.\n",
    "\n",
    "*Note:* In the estimate function, the variance function takes x as an argument. But we want to pass the `variance` function $\\mathbf{\\hat{X}}$ instead. <br>\n",
    "*Note 2:* In order to create the instrument, you need to create a lag matrix, and use `perm`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# FILL IN\n",
    "# Create first a lag matrix\n",
    "# Lag the lagged LMP variable\n",
    "# Finish writing the piv function\n",
    "# Finish writing the estimate function\n",
    "# Estimate using first differences and lagged first differences. Use the 2. lag as instrument."
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag(t):\n",
    "    # Create a lag matrix.\n",
    "    # Again remove the first observation, by removing the first row.\n",
    "    L_t = np.eye(t, k=-1)\n",
    "    return L_t[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lag yl, and then use it as an instrument for the lagged differences.\n",
    "L_t = lag(T)\n",
    "y_2l = lm.perm(L_t, y_l.reshape(-1, 1))\n",
    "ar1_iv_lvl_result = lm.estimate(\n",
    "    yfd, yfd_l, y_2l, robust_se=True, t=T-1\n",
    ")"
   ]
  },
  {
   "source": [
    "lm.print_table(\n",
    "    (ylbl, ['lag participation']), \n",
    "    ar1_iv_lvl_result, title='FD-IV AR(1)', floatfmt=['', '.3f', '.4f', '.2f']\n",
    ")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Your table should look like this:\n",
    "\n",
    "FD-IV AR(1) <br>\n",
    "Dependent variable: participation\n",
    "\n",
    "|                   |   Beta |     Se |   t-values |\n",
    "|-------------------|--------|--------|------------|\n",
    "| lag participation |  0.296 | 0.0469 |       6.30 |\n",
    "R² = 0.000 <br>\n",
    "σ² = 0.167"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 2\n",
    "Estimate eq. (2) by using the lag of the independent variable in first differences, $z_{it} = \\Delta LMP_{it-2}$ as an instrument."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN\n",
    "# Lag the first differenced lag LMP variable\n",
    "# The second lag uses up an extra observation, so you need to use the year variable to shorten both first differenced LMP and the 1. first difference lag.\n",
    "# Estimate using first differences and lagged first differences. Use the 2. first difference lag as instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new lag matrix (that is shorter, since we already removed one obs)\n",
    "# Create second lag of first differences.\n",
    "L_t = lag(T - 1)\n",
    "yfd_l2 = lm.perm(L_t, yfd_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first observation for each person.\n",
    "reduced_year = year[year != 1986]  # Remove first year, so that shape is the same as yfd\n",
    "yfd0 = yfd[reduced_year != 1987]\n",
    "yfd_l0 = yfd_l[reduced_year != 1987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_iv_result = lm.estimate(\n",
    "    yfd0, yfd_l0, yfd_l2, robust_se=True, t=T-2\n",
    ")\n",
    "lm.print_table(\n",
    "    (ylbl, ['lag participation']), \n",
    "    ar1_iv_result, title='FD-IV AR(1)', floatfmt=['', '.3f', '.4f', '.2f']\n",
    ")"
   ]
  },
  {
   "source": [
    "Your table should look like this:\n",
    "FD-IV AR(1) <br>\n",
    "Dependent variable: participation\n",
    "\n",
    "|                   |   Beta |     Se |   t-values |\n",
    "|-------------------|--------|--------|------------|\n",
    "| lag participation |  0.210 | 0.0880 |       2.39 |\n",
    "R² = 0.000 <br>\n",
    "σ² = 0.154"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Summing up Exercise 1 and 2.\n",
    "\n",
    "First of all, try to consider if it is more obvious to use $LMP_{it-2}$ or $\\Delta LMP_{it-2}$ as an instrument for $\\Delta LMP_{it-1}$?\n",
    "\n",
    "Then consider how do the different models compare to each other, some questions that you might discuss with your class mates could be:\n",
    "* Which ones do you feel gives most sense from an economic perspective. \n",
    "* Which ones gives most sense from an econometric perspective? \n",
    "* Do you feel that there is conclusive evidence that there is state dependence in female labour market participation?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Part 3: System 2SLS\n",
    "As mentioned earlier, we have $LMP_{it-2}^{\\textbf{o}} = (LMP_{i0}, LMP_{i1}, \\dotsc LMP_{it-2})$ available instruments at time $t$. In order to take advantage of these instruments, we could create the following instrument matrix,\n",
    "\n",
    "$$\n",
    "\\mathbf{Z^{\\mathbf{o}}} = \n",
    "\\begin{bmatrix}\n",
    "    y_{i0} & 0 & 0 & 0 & 0 & 0 & \\cdots & 0 \\\\\n",
    "    0 & y_{i0} & y_{i1} & 0 & 0 & 0 & \\cdots & 0 \\\\\n",
    "    0 & 0 & 0 & y_{i0} & y_{i1} & y_{i2} & \\cdots & 0 \\\\\n",
    "    \\vdots  & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & 0 & 0 & 0 & 0 & 0 & \\cdots & \\mathbf{y^o_{it-2}} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{pmatrix}\n",
    "t = 2 \\\\\n",
    "t = 3 \\\\\n",
    "t = 3 \\\\\n",
    "\\vdots \\\\\n",
    "t = T\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "We will use the `gmm` module for part, but parts of the `lm` module will be used in the `gmm` module."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Super short introduction to S2SLS, alse read Wooldridge (2010) chapter 5 and chapter 8\n",
    "\n",
    "Since we have different amount of instruments each period, we are unable to use these instruments using piv. We therefore have to leverage system two stage least square (S2SLS). \n",
    "\n",
    "To recap what (\"normal\") 2SLS looks like, eq. (3) would have been estimated this way if we used 2SLS,\n",
    "* In the first-stage regression, we estimate $\\mathbf{x}_K$ on $\\mathbf{Z}$, and then calculate the predicted $\\hat{\\mathbf{x}}_K$.\n",
    "* We use these predicted $\\hat{\\mathbf{x}}_K$ in our second stage regression, so for eq. (3), this would be to regress $\\mathbf{y}$ on $\\mathbf{x}_1, \\dotsc, \\mathbf{x}_{K-1}, \\hat{\\mathbf{x}}_K$.\n",
    "\n",
    "So for 2SLS, we perform a first stage regression for each time period, and store the predicted $\\hat{\\mathbf{x}}_K$ from each time period. We then combine these predicted observations (and we remember to do it in a way that the time periods are sorted correctly for each person) into one array, and use this in our second stage regression."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 1: Create the level instrument matrix $\\mathbf{Z^{\\mathbf{o}}}$\n",
    "\n",
    "Finish the function `sequential_instruments` in order to create the instrument matrix $\\mathbf{Z^{\\mathbf{o}}}$ using the second lag of LMP in **levels**. Note that you will not have one array that looks like $\\mathbf{Z^{\\mathbf{o}}}$, but an array that have something that looks like $\\mathbf{Z^{\\mathbf{o}}}$ for each individual in the data. Since we have four time periods, and access to $y_{i0}$, you should get three rows of instruments for each individual.\n",
    "\n",
    "If if is too difficult to create the instrument matrix $\\mathbf{Z^{\\mathbf{o}}}$, you could also in this instance hard code it. This can be done by using the year column to do boolean indexing in python. You can then use the `np.hstack` to create the necessary columns for the first stage regressions. Look at *question 2* below if you are uncertain on how many columns you should have for each regression."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_matrix = gmm.sequential_instruments(y_2l, T)\n",
    "print(instrument_matrix)"
   ]
  },
  {
   "source": [
    "To prepeare for next question, I have created an function that retrieves one time period for each person, and store them in seperate arrays, and finaly returns these in a list. (I also keep the array for the all time periods, since we need that for the second stage regression). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_eq_by_eq(x, t):\n",
    "    equation = []\n",
    "    # Reshape, so that each column is each time period\n",
    "    xt = x.reshape(-1, t)\n",
    "\n",
    "    # I then transpose this, so that each time period is in rows\n",
    "    for row in xt.T:\n",
    "        # I then put each time period in a separate array, that I store in the list.\n",
    "        equation.append(row.reshape(-1, 1))\n",
    "    # We need individual observations for all years in the second stage regression,\n",
    "    # so let us keep that at the end of the list.\n",
    "    equation.append(x)\n",
    "    return equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in your own variables for y and x\n",
    "y_arrays = xy_eq_by_eq(, T-1)\n",
    "x_arrays = xy_eq_by_eq(, T-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arrays = xy_eq_by_eq(yfd, T-1)\n",
    "x_arrays = xy_eq_by_eq(yfd_l, T-1)"
   ]
  },
  {
   "source": [
    "### Question 2: Use the instruments to perform 2SLS\n",
    "\n",
    "Now that you have the necessary instruments, use these to estimate eq. (2), with all possible lagged levels as instruments.\n",
    "\n",
    "I recommend that you create two functions for this. One that simply performs the first-stage regression given y and x, let's call it `first_stage`, and should return the predicted $\\hat{\\mathbf{x}}_K$, which in this case is the second lagged LMP.\n",
    "\n",
    "The second function, let us call is `system_2sls`, loops over a list of y, x and z arrays that are given as inputs, and performs the `first_stage` regression on each array (remember, each array has all observations from one time period only). Since the `first_stage` function you made returns the predicted $\\hat{\\mathbf{x}}_K$, you need to keep them, and in the end combine them. You can now perform the second-stage regression.\n",
    "\n",
    "So in our example where we use levels, you should perform three first-stage regressions that look like this:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Delta LMP_{i1987} & = \\rho_{11}LMP_{i1986} + u_{it} \\\\\n",
    "\\Delta LMP_{i1988} & = \\rho_{21}LMP_{i1986} + \\rho_{22}LMP_{i1987} + u_{it} \\\\\n",
    "\\Delta LMP_{i1989} & = \\rho_{31}LMP_{i1986} + \\rho_{32}LMP_{i1987} + \\rho_{33}LMP_{i1988} + u_{it} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Then, for each regression, you also need to predict the LMP. These need to be stored and in the end combined, so that you get a column that looks like this,\n",
    "\n",
    "$$\n",
    "\\underset{N(T - 1) \\times 1}{\n",
    "\\begin{pmatrix}\n",
    "    \\Delta \\widehat{LMP}_{1, 1987} \\\\\n",
    "    \\Delta \\widehat{LMP}_{1, 1988} \\\\\n",
    "    \\Delta \\widehat{LMP}_{1, 1989} \\\\\n",
    "    \\Delta \\widehat{LMP}_{2, 1987} \\\\\n",
    "    \\Delta \\widehat{LMP}_{2, 1988} \\\\\n",
    "    \\Delta \\widehat{LMP}_{2, 1989} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\Delta \\widehat{LMP}_{N, 1987} \\\\\n",
    "    \\Delta \\widehat{LMP}_{N, 1988} \\\\\n",
    "    \\Delta \\widehat{LMP}_{N, 1989} \\\\\n",
    "\\end{pmatrix}\n",
    "}\n",
    "$$\n",
    "\n",
    "So in the end, you perform a second stage regression that looks like this\n",
    "\n",
    "$$\n",
    "    \\Delta LMP_{it} = \\rho\\Delta \\widehat{LMP}_{it-1} + \\Delta u_{it}\n",
    "$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have created these helper functions. So if you managed to create the instrument matrix, you can use the iv_eq_by_eq to get columns that give you the correct number of columns for the different time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IV_eq_by_eq(instrument_matrix, reduced_year):\n",
    "    z_1987 = instrument_matrix[reduced_year == 1987, 0].reshape(-1, 1)\n",
    "    z_1988 = instrument_matrix[reduced_year == 1988, 1:3]\n",
    "    z_1989 = instrument_matrix[reduced_year == 1989, 3:]\n",
    "    return (z_1987, z_1988, z_1989)\n",
    "z_arrays = IV_eq_by_eq(instrument_matrix, reduced_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2sls_result = gmm.system_2sls(y_arrays, x_arrays, z_arrays)\n",
    "lm.print_table(\n",
    "    ('yfd', ['yfd_l']), s2sls_result, title='System 2SLS results', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "source": [
    "System 2SLS results <br>\n",
    "Dependent variable: yfd\n",
    "\n",
    "|       |   Beta |     Se |   t-values |\n",
    "|-------|--------|--------|------------|\n",
    "| yfd_l | 0.2390 | 0.0166 |    14.3891 |\n",
    "R² = 0.000 <br>\n",
    "σ² = 0.158"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 3\n",
    "Repeat question 1 and 2, but now with first differences as instruments. In other words, perform 2SLS with twice lagged first differences of LMP as instruments. \n",
    "\n",
    "I have given you some of the code if you managed to finish the `gmm.sequential_instruments` function. To create the y, x, and z arrays you use the provided `xy_eq_by_eq` function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_year2 = reduced_year[reduced_year != 1987]\n",
    "\n",
    "instrument_matrix = gmm.sequential_instruments(, T - 1)  # Input your second lag first differences variable\n",
    "def IV_eq_by_eq2(instrument_matrix, reduced_year):\n",
    "    z_1988 = instrument_matrix[reduced_year == 1988, 0].reshape(-1, 1)\n",
    "    z_1989 = instrument_matrix[reduced_year == 1989, 1:]\n",
    "    return (z_1988, z_1989)\n",
    "\n",
    "z_arrays = IV_eq_by_eq2(instrument_matrix, reduced_year2)\n",
    "y_arrays = # Fill in\n",
    "x_arrays = # Fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_year2 = reduced_year[reduced_year != 1987]\n",
    "instrument_matrix = gmm.sequential_instruments(yfd_l2, T - 1)\n",
    "def IV_eq_by_eq2(instrument_matrix, reduced_year):\n",
    "    z_1988 = instrument_matrix[reduced_year == 1988, 0].reshape(-1, 1)\n",
    "    z_1989 = instrument_matrix[reduced_year == 1989, 1:]\n",
    "    return (z_1988, z_1989)\n",
    "\n",
    "z_arrays = IV_eq_by_eq2(instrument_matrix, reduced_year2)\n",
    "y_arrays = xy_eq_by_eq(yfd0, T-2)\n",
    "x_arrays = xy_eq_by_eq(yfd_l0, T-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2sls_result = gmm.system_2sls(y_arrays, x_arrays, z_arrays)\n",
    "lm.print_table(\n",
    "    ('yfd', ['yfd_l']), s2sls_result, title='System 2SLS results', floatfmt='.4f',\n",
    "    tablefmt='github'\n",
    ")"
   ]
  },
  {
   "source": [
    "Your table should look something like this\n",
    "System 2SLS results <br>\n",
    "Dependent variable: yfd\n",
    "\n",
    "|       |   Beta |     Se |   t-values |\n",
    "|-------|--------|--------|------------|\n",
    "| yfd_l | 0.1959 | 0.0197 |     9.9622 |\n",
    "R² = 0.000 <br>\n",
    "σ² = 0.152"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Part 4: GMM\n",
    "Coming up"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_result = gmm.est_gmm(\n",
    "    W = la.inv(instrument_matrix.T@instrument_matrix), \n",
    "    y = yfd0,\n",
    "    x = yfd_l0,\n",
    "    z = instrument_matrix,\n",
    "    t = T-2,\n",
    "    step=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.print_table(('yfd', ['yfd_l']), gmm_result, title='GMM results', floatfmt='.4f', tablefmt='github')"
   ]
  }
 ]
}